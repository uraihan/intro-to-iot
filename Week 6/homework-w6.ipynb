{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# BL40A2010 Introduction to IoT-Based Systems\n\n## Assignment 6, DD.MM.YYYY\n\n### Author:",
   "metadata": {
    "collapsed": true,
    "cell_id": "00000-0df83db1-f804-4f8f-9aae-4bdef1a82350",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "**Prisoner's dilemma** is a standard example of a game analyzed in game theory that shows why two completely rational individuals might not cooperate, even if it appears that it is in their best interests to do so. It was originally framed by Merrill Flood and Melvin Dresher while working at RAND in 1950. Albert W. Tucker formalized the game with prison sentence rewards and named it \"prisoner's dilemma\", presenting it as follows:\n\n\"Two members of a criminal gang are arrested and imprisoned. Each prisoner is in solitary confinement with no means of communicating with the other. The prosecutors lack sufficient evidence to convict the pair on the principal charge, but they have enough to convict both on a lesser charge. Simultaneously, the prosecutors offer each prisoner a bargain. Each prisoner is given the opportunity either to betray the other by testifying that the other committed the crime, or to cooperate with the other by remaining silent. The possible outcomes are:\n\n- If A and B each betray the other (not-cooperating to each other), each of them serves $z$ years in prison (payoff of $-z$)\n- If A betrays B (not-cooperating with B) but B remains silent (cooperating with A), A will serve $y$ years in prison (payoff $-y$) and B will serve $w$ years  (payoff of $-w$).\n- If B betrays A (not-cooperating with A) but A remains silent (cooperating with B), B will serve $y$ years in prison (payoff $-y$) and A will serve $w$ years  (payoff of $-w$).\n- If A and B both remain silent, both of them will serve $x$ years in prison (payoff of $-x$).\"\n\nThe payoff table is presented below. \n\n|                | $B$ cooperates  | $B$ not-cooperating   |\n|----------------|:---------------:|--------------:|\n| $A$ cooperates |  $A \\rightarrow -x$   | $A\\rightarrow -w$  |\n|                |  $B\\rightarrow -x$   | $B\\rightarrow -y$  |\n|                |                 |               |\n| $A$ not-cooperating   |  $A\\rightarrow -y$   | $A\\rightarrow -z$  |\n|                |  $B\\rightarrow -w$   | $B\\rightarrow -z$  |\n\n**However, this is only a *Prisoner's Dilemma GAME* for A GIVEN RELATION between the years in prison (payoffs) as to be studied next.**\n\nps. Text adapted from [Wikipedia](https://en.wikipedia.org/wiki/Prisoner's_dilemma).",
   "metadata": {
    "cell_id": "00001-ef2890f9-3e6d-40ee-bfbb-e2c4786f20e2",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "**(1) Consider the Prisoner's dilemma description given above.**\n\n**(a) What is the relation between the payoffs values $x\\geq 0$, $y\\geq 0$, $w\\geq 0$ and $z \\geq 0$ so that the game can be classified as [Prisoner's Dilemma](https://en.wikipedia.org/wiki/Prisoner's_dilemma)?**\n\n**(b) Verify the results (i.e., the proposed inequality) with numerical examples using [nashpy](https://nashpy.readthedocs.io/en/stable/index.html). Please provide one example when the inequality holds and one it does not (check my example for Dove and Hawyk game).**",
   "metadata": {
    "cell_id": "00002-1279f431-c84b-4a49-b0db-99b872c17e5b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "a) To be classified as Prisoner's Dilemma, the payoff relationship is such that:\n - Mutual cooperation is superior to mutual defection. ($$x > z$$)\n - Defection is the dominant strategy for both parties. ($$y > x$$ and $$z > w$$)\n \n So to put it together, the relation would be **$$y > x > z > w$$** (meaning y is a better \"deal\" than x because the prisoner serves less time in prison)",
   "metadata": {
    "tags": [],
    "cell_id": "00003-f0da72af-2bad-4f5e-95b0-bf00be931978",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": false,
    "cell_id": "00003-b6fefdb6-45a4-4933-a972-5d944c556c66",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bcfeccd5",
    "execution_start": 1641930842756,
    "execution_millis": 9774,
    "deepnote_cell_type": "code"
   },
   "source": "!pip install nashpy",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting nashpy\n  Using cached nashpy-0.0.22.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25lerror\n\u001b[31m  ERROR: Command errored out with exit status 1:\n   command: /root/venv/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-35guhc0w/nashpy_98c541c3cb65453ca5fdede3025d98b1/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-35guhc0w/nashpy_98c541c3cb65453ca5fdede3025d98b1/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-vdq815xd\n       cwd: /tmp/pip-install-35guhc0w/nashpy_98c541c3cb65453ca5fdede3025d98b1/\n  Complete output (5 lines):\n  Traceback (most recent call last):\n    File \"<string>\", line 1, in <module>\n    File \"/tmp/pip-install-35guhc0w/nashpy_98c541c3cb65453ca5fdede3025d98b1/setup.py\", line 6, in <module>\n      with open(\"requirements.txt\") as f:\n  FileNotFoundError: [Errno 2] No such file or directory: 'requirements.txt'\n  ----------------------------------------\u001b[0m\n\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/93/1c/9005c6a0a3a3b183b5b216cc02cef14bb080fd3ee8733a1006fbcd81fffc/nashpy-0.0.22.tar.gz#sha256=9378fd492f01163ac01a7384dd94f7ffa3ce40e31fe2a08844a2e34576b3d8db (from https://pypi.org/simple/nashpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n\u001b[?25h  Downloading nashpy-0.0.21.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from nashpy) (1.19.5)\nRequirement already satisfied: scipy>=0.19.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from nashpy) (1.7.3)\nBuilding wheels for collected packages: nashpy\n  Building wheel for nashpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nashpy: filename=nashpy-0.0.21-py3-none-any.whl size=15282 sha256=d9f407c0234299555e2d8588e2af5327bf6eee4fe3f9789c01ecac4b47ea866c\n  Stored in directory: /root/.cache/pip/wheels/02/08/62/cf4fa931e0a317d180936b266169a57f4bb4eb801465bbe8a1\nSuccessfully built nashpy\nInstalling collected packages: nashpy\nSuccessfully installed nashpy-0.0.21\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-1160eb37-3641-47a5-b61c-04eb4f5d7393",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bb6c2c64",
    "execution_start": 1641930852542,
    "execution_millis": 683,
    "deepnote_cell_type": "code"
   },
   "source": "import numpy as np\nimport nashpy as nash",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Test 1: w < z < x < y\n\n|                | $B$ cooperates  | $B$ not-cooperating   |\n|----------------|:---------------:|--------------:|\n| $A$ cooperates |  $A \\rightarrow -x$   | $A\\rightarrow -w$  |\n|                |  $B\\rightarrow -x$   | $B\\rightarrow -y$  |\n|                |                 |               |\n| $A$ not-cooperating   |  $A\\rightarrow -y$   | $A\\rightarrow -z$  |\n|                |  $B\\rightarrow -w$   | $B\\rightarrow -z$  |\n\n$$\nA =\n\\begin{pmatrix}\n    -x & -w\\\\\n    -y & -z\n\\end{pmatrix}\\qquad\nB =\n\\begin{pmatrix}\n    -x & -y\\\\\n    -w & -z\n\\end{pmatrix}\n$$\n\n$$\nA =\n\\begin{pmatrix}\n    -1 & -3\\\\\n    0 & -2\n\\end{pmatrix}\\qquad\nB =\n\\begin{pmatrix}\n    -1 & 0\\\\\n    -3 & -2\n\\end{pmatrix}\n$$\n\nTo visualize it better, -1 means the prisoner will serve 1 more year in prison, 0 means the prisoner will be let go, etc.",
   "metadata": {
    "tags": [],
    "cell_id": "00006-b2f63f54-d041-4a8e-bc72-13865120b05e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00006-ffc89f25-e660-4e4f-8b4a-7a126a02936b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "119f96d4",
    "execution_start": 1641930853233,
    "execution_millis": 15,
    "deepnote_cell_type": "code"
   },
   "source": "x = -1\ny = 0 \nz = -2\nw = -3",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00008-2aeab5f2-078d-4010-a077-fae7909c452b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c12ece4c",
    "execution_start": 1641930853255,
    "execution_millis": 30,
    "deepnote_output_heights": [
     174.6875
    ],
    "deepnote_cell_type": "code"
   },
   "source": "A = np.array([[x, w], [y, z]])\nB = np.array([[x, y], [w, z]])\nprisoners_dilemma = nash.Game(A, B)\nprisoners_dilemma",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "text/plain": "Bi matrix game with payoff matrices:\n\nRow player:\n[[-1 -3]\n [ 0 -2]]\n\nColumn player:\n[[-1  0]\n [-3 -2]]"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-19436196-a2f3-4351-a806-2354bedefd42",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "499a9d48",
    "execution_start": 1641930853290,
    "execution_millis": 3,
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_cell_type": "code"
   },
   "source": "eqs = prisoners_dilemma.support_enumeration()\nlist(eqs)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 5,
     "data": {
      "text/plain": "[(array([0., 1.]), array([0., 1.]))]"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The results above is a Nash equilibrium where both betrays (dominant strategy)",
   "metadata": {
    "tags": [],
    "cell_id": "00010-aaee742e-ef96-4f0a-9d17-0cb1fdcd9e55",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Test 2: x > y (x better deal than y)\n\n|                | $B$ cooperates  | $B$ not-cooperating   |\n|----------------|:---------------:|--------------:|\n| $A$ cooperates |  $A \\rightarrow 0$   | $A\\rightarrow -3$  |\n|                |  $B\\rightarrow 0$   | $B\\rightarrow -1$  |\n|                |                 |               |\n| $A$ not-cooperating   |  $A\\rightarrow -1$   | $A\\rightarrow -2$  |\n|                |  $B\\rightarrow -3$   | $B\\rightarrow -2$  |\n\n\n$$\nA =\n\\begin{pmatrix}\n    0 & -3\\\\\n    -1 & -2\n\\end{pmatrix}\\qquad\nB =\n\\begin{pmatrix}\n    0 & -1\\\\\n    -3 & -2\n\\end{pmatrix}\n$$\nx = 0\ny = -1\nw = -3\nz = -2",
   "metadata": {
    "tags": [],
    "cell_id": "00011-a2313092-ca1f-48d8-a52d-6dc22617e3c4",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00011-fa0a12c2-785c-4eb3-8348-a1ae30e84e39",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2a6c6f61",
    "execution_start": 1641931155550,
    "execution_millis": 2,
    "deepnote_output_heights": [
     174.6875
    ],
    "deepnote_cell_type": "code"
   },
   "source": "C = [[0, -3], [-1, -2]]\nD = [[0, -1], [-3, -2]]\nprisoners_dilemma2 = nash.Game(C,D)\nprisoners_dilemma2",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 8,
     "data": {
      "text/plain": "Bi matrix game with payoff matrices:\n\nRow player:\n[[ 0 -3]\n [-1 -2]]\n\nColumn player:\n[[ 0 -1]\n [-3 -2]]"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00013-3a0b2093-d1fa-44a6-bffb-eb4b64528eb1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d109841",
    "execution_start": 1641931157883,
    "execution_millis": 21,
    "deepnote_output_heights": [
     59.5625
    ],
    "deepnote_cell_type": "code"
   },
   "source": "eqs2 = prisoners_dilemma2.support_enumeration()\nlist(eqs2)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 9,
     "data": {
      "text/plain": "[(array([1., 0.]), array([1., 0.])),\n (array([0., 1.]), array([0., 1.])),\n (array([0.5, 0.5]), array([0.5, 0.5]))]"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The first two lines output:\n- In the first line, Player A (first array) will cooperate with probability $1$ and betrays with probability $0$; Player B (second array) will cooperate with probability $1$ and betrays with probability $0$.\n- In the first line, Player A (first array) will cooperate with probability $0$ and betrays with probability $1$; Player B (second array) will cooperate with probability $0$ and betrays with probability $1$.\nThis satisfies the classification of the Prisoner's Dilemma game, meaning either both will confess or both cooperate. However, there is another Nash equilibrium (mixed strategy) in the third line:\n- Player A (first array) will cooperate with probability $1/3$ and betrays with probability $3/4$; Player B (second array) will cooperate with probability $1/3$ and betrays with probability $3/4$.",
   "metadata": {
    "tags": [],
    "cell_id": "00014-37f670ff-9715-4e3f-b0eb-72518dfd3517",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "**(2) Justify why the game from the previous exercise is or is not a good (reasonable) model when $A$ and $B$ are:**\n\n**1. Two trained members from the army when they are in prison.**\n\n\n**2. Competitive companies in the market discussing standardization.**\n\n\n**3. Two different autonomous IoT-based home energy management algorithms that are focus on energy efficiency.**\n\n\n**4. Two different autonomous IoT-based home energy management algorithms that are focus on profit maximization.**\n\n**ps. You need to think about the assumption used in Game Theory and in the Prisoner's dilemma problem setting.**",
   "metadata": {
    "cell_id": "00004-9da010a7-8c5e-4d76-8161-46a3259f9754",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Answer: \\\n1. Probably yes, but it could be no if we consider a trained member of an army have loyalty to their armed force and its members, which does not fulfill the required condition for prisoner's dilemma game.\n2. No, if we consider standardization of public goods that is used by multiple countries, such as shipping containers and inter-continental train system. Using the prisoner's dilemma model, both companies **would not lose if they're both having different standards**, which is **not applicable** to standardization where having two standards for the same product is highly undesirable.\n3. No, because both algorithms can work in cooperation with each other and energy efficiency of house A does not affect the payout of house B.\n4. Yes. If the energy management of house A betrays, then A will get a significantly higher profit than B and vice versa. Of course, cooperation between both energy management algorithms is more beneficial than if both algorithms betray against each other, but even if both betray against each other it is still better than if one algorithm cooperate and the other betrays.",
   "metadata": {
    "cell_id": "00005-f824e7a2-90fe-410c-8f05-f660b355b7dc",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6e014854-0d33-4882-b3ba-5e4227a689e6' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "deepnote_notebook_id": "8b73cb06-1109-4539-be70-78a011851cc0",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}